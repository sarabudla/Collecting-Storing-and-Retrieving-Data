---
title: "Practicum 3"
author: "Nithya Sarabudla, Maryanne Muchuki, Reina Conti"
date: "2023-12-10"
output: pdf_document
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Practicum 3
This is an R Markdown document of solutions to the questions for Practicum 3.

```{r message=FALSE}
# loading required packages 
library(dplyr)
library(tidyverse) 
library(ggplot2) 
library(corrplot) 
library(FNN) 
library(caret) 
library(psych) 
```

## Question 1
Load data set from csv into data frame. 
```{r}
# Reading data into a data frame
df <- read.csv("2018_Green_Taxi_Trip_Data.csv")
str(df)
summary(df)
```

### Data exploration. 
A distribution of the tip amounts visualized. 
```{r}
# distribution of the tip amount
ggplot(df, aes(x = tip_amount)) +
  geom_histogram(binwidth = 10) + 
  scale_y_log10() + 
  labs(title = "Distribution of the tip amount",
       caption = "Log-scaled histogram showing the distribution of tip amounts",
       x = "Tip Amount ($)")
       ylab("Frequency (log-scaled)")
```
The data for tip amounts is skewed to the right as most of the values hover just above 0. There are several higher values that extend past 100. 
```{r}
# correlation matrix between variables
correlation_matrix <- cor(select_if(df, is.numeric))
print(correlation_matrix)
```
Correlation matrix to see correlation between all numeric values. 
"tip_amount" has a positive correlation with "trip_distance" and "tolls_amount," and a negative correlation with "payment_type."

```{r}
# Missing values
as.matrix(apply(is.na(df), 2, sum))
```
There are not many missing values for the data, except for ehail_fee where there are 1,048,575 missing values.

```{r}
# Tip amount outliers
ggplot(df, aes(x = tip_amount)) +
  geom_boxplot() + 
  scale_x_log10() + 
  labs(title = "Box plot of outliers of tip amount",
       caption = "Box plot highlighting potential outliers in the tip amount distribution") +
       xlab("Tip Amount ($)") +
  ylab("Frequency (log-scaled)")

summary(df$tip_amount)
```

In the above codes , data has been imported into a data frame, with the primary focus on the 'tip_amount' variable as the target. Histogram and box plots were generated to visualize the distribution and identify outliers. Given that a substantial portion of the values clusters around 0 and there are prominent outliers, log10 transformation was applied to the plot axes for better visualization. The resulting plots clearly illustrate that the majority of the data is concentrated around 0, while outliers extend up to 250.


```{r}
# Performing data pre-processing steps to be able to compute correlations
# Removing "," from values and converting into numeric type
df <- df %>% 
  mutate_at(vars(total_amount, fare_amount), 
            function (x) {as.numeric(gsub(",", "", x))})

# Converting pickup and drop time stamps to datetime format
df <- df %>% 
  mutate_at(vars(ends_with("datetime")), 
                       function (x) {as.POSIXct(x, format='%m/%d/%Y %H:%M')})
```

### Feature Selection

Identify features/variables that are good indicators for tip amount.
```{r}
# Calculate mode for trip_type
most_frequent_trip_type <- df %>%
  group_by(trip_type) %>%
  summarise(count = n()) %>%
  filter(count == max(count)) %>%
  pull(trip_type)

# Impute missing values in trip_type with the most frequent value
df <- df %>%
  mutate(trip_type = if_else(is.na(trip_type), 
                             most_frequent_trip_type, 
                             trip_type))

# Compute correlations on the entire data frame (numeric columns only)
correlation_matrix_all <- cor(select_if(df, is.numeric))
# Generate a correlation heat map for all variables
corrplot(correlation_matrix_all, tl.col = "black", diag=FALSE, rect.col="white")
```
The heatmap visually represents correlation coefficients among various variables in the dataset. Larger, darker circles on the heatmap signify more robust correlations, whether positive or negative.

```{r}
# Identify columns with helpful correlations with the target (tip_amount)
selected_features <- c("trip_distance", 
                       "tip_amount", 
                       "fare_amount", 
                       "tolls_amount", 
                       "payment_type", 
                       "total_amount")

# Create a new dataframe with the selected features
df_selected <- df[, selected_features]
# Generate a new correlation plot for selected features
corrplot(cor(df_selected), diag = FALSE, rect.col = "white", tl.col = "black")

# Generate scatter plot matrices for selected features
pairs.panels(df_selected)
```

In the code, the handling of missing values in the trip_type column involved the imputation of the most frequently occurring value. Subsequently, the entire dataset was employed to calculate correlations, leading to the generation of a correlation heat map using the corrplot library. Upon scrutinizing the heat map, notable patterns emerged. Positive correlations were identified between tip_amount and variables such as trip_distance and fare_amount. Additionally, a modest positive correlation was observed between tip_amount and tolls_amount, while a negative correlation with payment_type was evident, attributable to the absence of recorded cash tips in the dataset. Moreover, total_amount exhibited a relatively stronger positive correlation with tip_amount. In response to these insights, the dataset was refined by filtering for columns showcasing significant correlations with tip_amount, and the remaining columns were excluded from further analysis.

### Feature engineering:
### Bonus 

```{r}
# Extract hour of day from pickup time
df$hour_of_day <- hour(df$lpep_pickup_datetime)

```

```{r}
# Calculate correlation coefficient
correlation_hour <- cor(df$hour_of_day, df$tip_amount, use="complete.obs")

# Box plot
boxplot(df$tip_amount ~ df$hour_of_day, main="Box Plot of Hour of Day vs. Tip Amount", 
        xlab="Hour of Day", ylab="Tip Amount", col="lightblue")

# Print correlation coefficient
cat("Correlation Coefficient (Hour of Day):", correlation_hour, "\n")

```


The correlation coefficient between the "hour_of_day" and "tip_amount" is approximately 0.0036. This value is very close to zero, indicating a very weak linear relationship between the hour of the day and the tip amount. In other words, there is almost no discernible correlation between the time of day a trip occurs and the tip amount.
The lack of a strong correlation suggests that the "hour_of_day" feature may not be a significant predictor of tip amounts in this dataset. 

```{r}
# Extract day of week from pickup date
df$day_of_week <- weekdays(df$lpep_pickup_datetime)

```

```{r}
# Convert date-time columns to POSIXct format
df$lpep_pickup_datetime <- as.POSIXct(df$lpep_pickup_datetime, format="%m/%d/%Y %H:%M")

# Extract day of week from pickup date
df$day_of_week <- weekdays(df$lpep_pickup_datetime)

# Convert day_of_week to a factor
df$day_of_week <- factor(df$day_of_week, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

# Calculate correlation coefficient
correlation_day <- cor(as.numeric(df$day_of_week), df$tip_amount, use="complete.obs")

# Box plot
boxplot(df$tip_amount ~ as.numeric(df$day_of_week),
        main="Box Plot of Day of Week vs. Tip Amount",
        xlab="Day of Week", ylab="Tip Amount", col="lightgreen",
        names=c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"))

# Print correlation coefficient
cat("Correlation Coefficient (Day of Week):", correlation_day, "\n")



```

The correlation coefficient between the "Day of Week" and "Tip Amount" is 0.002765401. This coefficient is very close to zero, indicating a weak correlation between the day of the week and the tip amount. Additionally, the box plot does not show significant variations in tip amounts across different days of the week.

## Question 2

### Data Preparation

I have done the imputing missing values and transformations steps in the question 1 because to generate the correlation figures 

```{r}
# Reshaping data for a combined box plot
df_long <- gather(df_selected, key = "feature", value = "measurement")

# Create box plots for each feature
ggplot(df_long, aes(x = feature, y = measurement)) +
  geom_boxplot() +
  xlab("Feature") +
  ylab("Measurement") + 
  labs(title = "Box plots for each feature",
       caption = "A plot to examine outliers")

# Percentage of rows with tip amounts exceeding 40
tip_above_40_percentage <- nrow(df[df$tip_amount > 40, ]) / nrow(df)
cat("Percentage of rows with tip above 40:", tip_above_40_percentage, "\n")

# Filtering rows with tip_amount under 40 and total and fare amounts under 200
# Also removing negative amounts to mitigate outliers
df_filtered <- df_selected %>% 
  filter_at(vars(ends_with("amount")), function(x) {(x <= 200) & (x >= 0)}) %>% 
  filter(tip_amount < 40)

removed_rows <- nrow(df) - nrow(df_filtered)
cat("Removed rows:", removed_rows, "\n")

# Function to identify a numeric column
is_numeric_column <- function(x) is.numeric(x) && !identical(x, df_filtered$tip_amount)

# Z-score normalization
df_zscored <- df_filtered %>%
  mutate_if(is_numeric_column, function(x) (x - mean(x)) / sd(x))

# Define the target variable
target_variable <- df_zscored$tip_amount

# Setting a random seed for result reproducibility
set.seed(777)
# Shuffling the dataset
df_shuffled <- df_zscored[sample(nrow(df_zscored)), ]
# Splitting the dataset into training and test sets in an 80:20 ratio
train_indices <- createDataPartition(target_variable, p = 0.8, list = FALSE)
df_train <- df_shuffled[train_indices, ]
df_test <- df_shuffled[-train_indices, ]
```

The data preprocessing phase involves examining the data distribution through box plots, revealing significant outliers, particularly in the total_amount and fare_amount columns.

A minimal percentage (7.34e-05) of values exhibit a tip_amount above 40, indicating potential anomalies. Additionally, negative values in these amounts are nonsensical.

To address this, rows with tip_amount above 40, and rows with total and fare amounts exceeding 200, are removed. Negative values in these columns are also eliminated.

Numeric columns, excluding tip_amount, undergo standardization, ensuring a mean of 0 and a standard deviation of 1, effectively normalizing the data.

The dataset is then randomly shuffled, and an 80:20 split is applied, with 80% assigned to the training set and the remaining 20% to the testing set. This split is deemed suitable due to the dataset's substantial number of instances.

## Question 3
Function knn.predict implemented to predict tip for each observation in data_test.
```{r}
# Define a function, knn.predict, for making predictions using k-nearest neighbors regression.
# Arguments:
#   - data_train: Training dataset containing observations and 'tip_amount'.
#   - data_test: Testing dataset for which 'tip_amount' predictions are made.
#   - k: Number of neighbors to consider in the k-nearest neighbors algorithm.

knn.predict <- function(data_train, data_test, k) {
  # Identify the index of the 'tip_amount' column in the training dataset.
  tip_amount_index <- which(colnames(data_train) == "tip_amount")
  
  # Extract features (X) and target variable (y) for the training set.
  X_train <- data_train[, -tip_amount_index]
  y_train <- data_train[, tip_amount_index]
  
  # Extract features (X) for the testing set.
  X_test <- data_test[, -tip_amount_index]
  
  # Perform k-nearest neighbors regression on the training set and make predictions for the testing set.
  knn_predictions <- knn.reg(train = X_train, test = X_test, y = y_train, k = k)$pred
  
  # Calculate the Mean Squared Error (MSE) between the predicted and actual 'tip_amount' in the testing set.
  mse <- mean((knn_predictions - data_test[, tip_amount_index])^2)
  
  # Return the MSE score.
  return(mse)
}

# Test the knn.predict function with training and testing datasets, using k=3.
knn.predict(df_train, df_test, k = 3)

```

The result, [1] 0.1027348, represents the Mean Squared Error (MSE) calculated by the knn.predict function. This function uses training data to build a k-nearest neighbors (KNN) regression model and makes predictions on testing data. The squared differences between these predictions and actual labels are averaged to compute the MSE, indicating the accuracy of the model in predicting 'tip_amount' for the test set.

## Question 4
Evaluation.
```{r}
# Define a range of values for k
k_values <- seq(3, 25, 1)

# Initialize an empty vector to store MSE scores
mse_scores <- rep(NA, length(k_values))

# Iterate over the range of k values and perform k-nn predictions
for (i in seq_along(k_values)) {
    mse_scores[i] <- knn.predict(df_train, df_test, k_values[i])
}

# Create a data frame to store results
results_data <- data.frame(k = k_values, MSE = mse_scores)

# Plot the MSE scores against different values of k
ggplot(data = results_data, aes(x = k, y = MSE)) + 
  geom_line() + 
  geom_point() + 
  labs(title = "Effect of k on MSE",
       subtitle = "Determining the Optimal k in k-NN Regression",
       x = "Number of Neighbors (k)",
       y = "Mean Squared Error (MSE)",
       caption = "A plot illustrating how the choice of k impacts the MSE in k-NN regression.")

```

This graph shows the effect of changing the k value on the mean squared error of the prediction made by the knn function. The values of k graphed here range from 3-25 with the lowest MSE occuring when k is equal to 5. There is an increase in MSE with every incremented value for k after k is equal to 5. For this reason the value of k that is most suitable is 5. 

```{r}
print(results_data)
```
Table with values of k and corresponding MSE.

We would advocate for using the model to predict the tip amount on future trips because the mean squared error for the value of k we have chosen is close to 0 which indicates accurate predictions. This model can be used to accurately predict what the tip amount will be or get close to what the value is likely to be. 

## Question 5
Optimize k-nn model and evaluate the effect of the percentage split. 
```{r}
# Function to evaluate different split ratios
evaluate_split_ratio <- function(data, ratios, k) {
  results <- data.frame()
  
  for (ratio in ratios) {
    # split the data into training and test sets
    split_index <- floor(nrow(data) * ratio)
    data_train <- data[1:split_index, ]
    data_test <- data[(split_index + 1):nrow(data), ]
    
    # call the knn predict function with the specified split ratio and k
    mse <- knn.predict(data_train, data_test, k)
    
    # store the results in a data frame
    results <- rbind(results, data.frame(Ratio = ratio, MSE = mse))
  }
  
  return(results)
}
```

```{r}
# Define different split ratios to evaluate
split_ratios <- c(0.7, 0.75, 0.8, 0.85, 0.9)

# Specify the value of k
k_value <- 3

# Evaluate different split ratios
evaluation_results <- evaluate_split_ratio(df_train, split_ratios, k_value)

# Print the results
print(evaluation_results)

```

```{r}
# Create a plot
ggplot(evaluation_results, aes(x = Ratio, y = MSE)) +
  geom_line() +
  geom_point() +
  labs(title = "Effect of Split Ratio on MSE",
       x = "Training Set Ratio",
       y = "Mean Squared Error")
```
The MSE decreases as the split ratio increases from 0.70 to 0.90.
The lowest MSE is observed at the 0.90 split ratio (0.09950455).
A lower MSE suggests that the model's predictions are closer to the actual values.
In this case, the 0.90 split ratio appears to result in better predictive performance compared to other ratios.
The graph shows the relationship between the training set ratio and the mean squared error of the predictions when generated with that ratio. Lower ratios tend to have a higher mean squared error. The ratio that we had tested before was 80/20. Increasing the percentage for the training set to 85 does not lower the MSE by any significant amount. In order to improve the prediction for the model, the training set ratio could be set to 90 as this ratio comes with the lowest mean squared error, though the difference with the original 80/20 split is not that great. 
